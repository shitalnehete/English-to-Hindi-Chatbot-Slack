{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e144a894",
   "metadata": {},
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb2b25",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6692864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder model\n",
    "encoder_model = tf.keras.models.load_model('models/seq2seq_encoder_eng_hin.hd5')\n",
    "\n",
    "#Decoder model\n",
    "decoder_model = tf.keras.models.load_model('models/seq2seq_decoder_eng_hin.hd5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d9cc24",
   "metadata": {},
   "source": [
    "### Load tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "encoder_t = pickle.load(open('models/encoder_tokenizer_eng','rb'))\n",
    "decoder_t = pickle.load(open('models/decoder_tokenizer_hin','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c808ef1",
   "metadata": {},
   "source": [
    "### Define Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 22 #From the training\n",
    "max_decoder_seq_length = 27 #From the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bdfc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b142d7",
   "metadata": {},
   "source": [
    "### Function to generate Padded sequences for Input string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input(input_str):\n",
    "    \n",
    "    #Convert words to indexes\n",
    "    encoder_seq = encoder_t.texts_to_sequences([input_str])\n",
    "    \n",
    "    #Pad sequences\n",
    "    encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq, \n",
    "                                                                       maxlen=max_encoder_seq_length, \n",
    "                                                                       padding='post')\n",
    "    return encoder_input_data  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c72729",
   "metadata": {},
   "source": [
    "### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89828e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def decode_sentence(input_str):\n",
    "    \n",
    "    #Convert input string to padded sequence\n",
    "    input_seq = encode_input(input_str)\n",
    "    \n",
    "    #Get the encoder state values\n",
    "    decoder_initial_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    #Build a sequence with '<start>' - starting sequence for Decoder\n",
    "    target_seq = np.zeros((1,1))    \n",
    "    target_seq[0][0] = decoder_t.word_index['<start>']\n",
    "    \n",
    "    #flag to check if prediction should be stopped\n",
    "    stop_loop = False\n",
    "    \n",
    "    #Initialize predicted sentence\n",
    "    predicted_sentence = ''\n",
    "    \n",
    "    #start the loop\n",
    "    while not stop_loop:\n",
    "        \n",
    "        predicted_outputs, h, c = decoder_model.predict([target_seq] + \n",
    "                                                        decoder_initial_states_value)\n",
    "        \n",
    "        #Get the predicted output with highest probability\n",
    "        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
    "        \n",
    "        #Get the predicted word from predicter integer\n",
    "        predicted_word = int_to_word_decoder[predicted_output]\n",
    "        \n",
    "        #Check if prediction should stop\n",
    "        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n",
    "            \n",
    "            stop_loop = True\n",
    "            continue\n",
    "                    \n",
    "        #Updated predicted sentence\n",
    "        if (len(predicted_sentence) == 0):\n",
    "            predicted_sentence = predicted_word\n",
    "        else:\n",
    "            predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
    "            \n",
    "        #Update target_seq to be the predicted word index\n",
    "        target_seq[0][0] = predicted_output\n",
    "        \n",
    "        #Update initial states value forr decoder\n",
    "        decoder_initial_states_value = [h,c]\n",
    "        \n",
    "    \n",
    "    return predicted_sentence\n",
    "In [ ]:\n",
    "if __name__== '__main__':\n",
    "    print(decode_sentence('I'm starving.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239328c",
   "metadata": {},
   "source": [
    "### Test Decode function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_sentence(\"I'm starving.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e486801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
